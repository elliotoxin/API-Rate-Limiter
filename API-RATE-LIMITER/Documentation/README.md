# Advanced API Rate Limiter

A production-grade, feature-rich Python implementation of multiple rate limiting algorithms with distributed support via Redis.

## ğŸ¯ Features

### Multiple Rate Limiting Algorithms

1. **Token Bucket** - Allows burst traffic while maintaining average rate
   - Best for: APIs needing burst handling
   - Pros: Smooth traffic shaping, efficient
   - Cons: More memory per client

2. **Sliding Window** - Precise request counting in rolling time window
   - Best for: Strict rate limiting requirements
   - Pros: Accurate, no boundary issues
   - Cons: Higher memory usage

3. **Leaky Bucket** - Smooth traffic at fixed rate
   - Best for: Preventing sudden spikes
   - Pros: Predictable behavior, queue management
   - Cons: May reject bursty legitimate traffic

4. **Fixed Window** - Simple counter reset at boundaries
   - Best for: Simple use cases
   - Pros: Low memory, fast
   - Cons: Edge-case issues at boundaries

### Advanced Features

- **Distributed Support**: Redis-based implementation for multi-server deployments
- **Multiple Storage Backends**: In-memory and distributed Redis storage
- **Per-Client Limits**: Different rate limits for different API keys/users
- **Comprehensive Metrics**: Status tracking and statistics
- **Thread-Safe**: Handles concurrent requests safely
- **Flexible Configuration**: Easily customizable parameters
- **Production-Ready**: Error handling, logging, monitoring

## ğŸ“¦ Installation

### Requirements
- Python 3.8+
- Flask (for API server)
- Redis (optional, for distributed mode)

### Setup

```bash
# Clone the repository
git clone <repo-url>
cd api-rate-limiter

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install flask redis

# Optional: Start Redis server
redis-server
```

## ğŸš€ Quick Start

### Basic Usage

```python
from rate_limiter import RateLimitConfig, RateLimitAlgorithm, RateLimiterFactory

# Configure rate limiter
config = RateLimitConfig(
    max_requests=100,
    time_window=60,
    algorithm=RateLimitAlgorithm.TOKEN_BUCKET
)

# Create limiter
limiter = RateLimiterFactory.create(config)

# Check if request is allowed
response = limiter.is_allowed('client_id')
if response.allowed:
    # Process request
    print(f"Request allowed. Remaining: {response.remaining}")
else:
    # Rate limit exceeded
    print(f"Rate limited. Retry after: {response.retry_after}s")
```

### Flask Integration

```python
from app import app, rate_limiter, RateLimitAlgorithm

@app.route('/api/data')
@rate_limiter.limit(
    max_requests=100,
    time_window=60,
    algorithm=RateLimitAlgorithm.TOKEN_BUCKET
)
def get_data():
    return {'data': 'value'}
```

### Distributed Setup with Redis

```python
config = RateLimitConfig(
    max_requests=1000,
    time_window=3600,
    algorithm=RateLimitAlgorithm.SLIDING_WINDOW,
    distributed=True,
    redis_url="redis://localhost:6379/0"
)

limiter = RateLimiterFactory.create(config)
```

## ğŸ”§ Configuration

### RateLimitConfig Parameters

```python
RateLimitConfig(
    max_requests=100,           # Maximum requests allowed
    time_window=60,             # Time window in seconds
    algorithm=ALGORITHM,        # Rate limiting algorithm
    burst_size=None,            # Max burst for token bucket
    refill_rate=None,           # Custom refill rate (tokens/sec)
    distributed=False,          # Use Redis
    redis_url="redis://..."     # Redis connection URL
)
```

### Algorithm Selection

**Token Bucket** - Best for most use cases
```python
config = RateLimitConfig(
    max_requests=100,
    time_window=60,
    algorithm=RateLimitAlgorithm.TOKEN_BUCKET,
    burst_size=150  # Allow 150 tokens burst
)
```

**Sliding Window** - For strict accuracy
```python
config = RateLimitConfig(
    max_requests=50,
    time_window=10,
    algorithm=RateLimitAlgorithm.SLIDING_WINDOW
)
```

**Leaky Bucket** - For traffic smoothing
```python
config = RateLimitConfig(
    max_requests=100,
    time_window=60,
    algorithm=RateLimitAlgorithm.LEAKY_BUCKET
)
```

**Fixed Window** - For simple cases
```python
config = RateLimitConfig(
    max_requests=1000,
    time_window=3600,
    algorithm=RateLimitAlgorithm.FIXED_WINDOW
)
```

## ğŸ“Š API Response Headers

Rate limit information is included in response headers:

```
X-RateLimit-Limit: 100          # Max requests in window
X-RateLimit-Remaining: 47       # Requests remaining
X-RateLimit-Reset: 1234567890   # Unix timestamp when limit resets
Retry-After: 30                 # Seconds to wait (if rate limited)
```

## ğŸ§ª Testing

### Run Tests

```bash
python test_rate_limiter.py
```

### Run Benchmarks

```python
python test_rate_limiter.py  # Includes benchmarks at end
```

### Test Coverage

- âœ… All algorithms tested
- âœ… Edge cases and boundary conditions
- âœ… Concurrent request handling
- âœ… Token refill mechanisms
- âœ… Window expiration
- âœ… Reset functionality

## ğŸ“ˆ Performance

Benchmark results (100,000 requests on standard hardware):

```
TokenBucket       - ~500,000 req/s
SlidingWindow     - ~300,000 req/s
LeakyBucket       - ~400,000 req/s
FixedWindow       - ~600,000 req/s
```

Redis-based (distributed):
```
Distributed       - ~50,000 req/s (network overhead included)
```

## ğŸ—ï¸ Architecture

### Class Hierarchy

```
BaseRateLimiter (Abstract)
â”œâ”€â”€ TokenBucketLimiter
â”œâ”€â”€ SlidingWindowLimiter
â”œâ”€â”€ LeakyBucketLimiter
â”œâ”€â”€ FixedWindowLimiter
â””â”€â”€ DistributedRateLimiter
```

### Data Structures

**Token Bucket:**
```python
{
    'tokens': 95.5,           # Current tokens
    'last_refill': 1234567.8, # Last refill timestamp
    'burst_size': 100         # Max tokens
}
```

**Sliding Window:**
```python
deque([                       # Timestamps of requests
    1234567.1,
    1234567.2,
    1234567.3,
    ...
])
```

**Leaky Bucket:**
```python
{
    'queue': deque([...]),    # Queued requests
    'last_leak_time': ...,    # Last leak timestamp
    'total_leaked': 100       # Total leaked requests
}
```

**Fixed Window:**
```python
{
    'count': 45,              # Current count
    'window_start': 1234567.0 # Window start time
}
```

## ğŸ”’ Security Considerations

1. **Client Identification**
   - Use API keys for authenticated clients
   - IP-based fallback for anonymous users
   - Implement proper key management

2. **Distributed Deployments**
   - Use secure Redis connections (TLS)
   - Implement Redis authentication
   - Use separate Redis instances per environment

3. **Abuse Prevention**
   - Monitor for rate limit evasion
   - Implement progressive backoff
   - Log suspicious activity

4. **Privacy**
   - Don't log sensitive data
   - Clean up old rate limit entries
   - Use secure client IDs

## ğŸ› Troubleshooting

### Redis Connection Issues

```python
# Check Redis connection
config = RateLimitConfig(..., distributed=True)
try:
    limiter = RateLimiterFactory.create(config)
except Exception as e:
    print(f"Redis error: {e}")
    # Fallback to in-memory
    config.distributed = False
    limiter = RateLimiterFactory.create(config)
```

### High Memory Usage

- Switch from Sliding Window to Token Bucket
- Reduce time_window for Sliding Window
- Implement cleanup for old entries
- Use Redis for distributed deployments

### Inconsistent Limits Across Instances

- Use Redis-based distributed limiter
- Ensure all instances use same configuration
- Check for clock skew in servers

## ğŸ“š Examples

### Example 1: API with Tiered Limits

```python
@app.route('/api/public')
@rate_limiter.limit(max_requests=100, time_window=60)
def public_api():
    return {'data': 'public'}

@app.route('/api/premium')
@rate_limiter.limit(max_requests=1000, time_window=60)
def premium_api():
    return {'data': 'premium'}
```

### Example 2: Per-User Rate Limiting

```python
def get_user_id():
    return request.headers.get('X-User-ID', request.remote_addr)

@app.route('/api/data')
@rate_limiter.limit(
    max_requests=50,
    time_window=60,
    key_func=get_user_id
)
def get_data():
    return {'data': 'value'}
```

### Example 3: Distributed Rate Limiting

```python
# Single configuration used across all instances
config = RateLimitConfig(
    max_requests=10000,
    time_window=3600,
    algorithm=RateLimitAlgorithm.SLIDING_WINDOW,
    distributed=True,
    redis_url="redis://redis-cluster:6379/0"
)

limiter = RateLimiterFactory.create(config)
```

### Example 4: Custom Rate Limit Keys

```python
def get_api_key():
    return request.headers.get('X-API-Key')

@app.route('/api/write', methods=['POST'])
@rate_limiter.limit(
    max_requests=10,
    time_window=60,
    key_func=get_api_key
)
def write_data():
    data = request.get_json()
    return {'id': 12345}, 201
```

## ğŸš¦ Response Codes

- **200** - Request successful, rate limit OK
- **201** - Resource created, rate limit OK
- **429** - Too Many Requests (rate limited)
- **500** - Internal server error

### 429 Response Format

```json
{
    "error": "Rate limit exceeded",
    "message": "Maximum 100 requests per 60s allowed",
    "retry_after": 30,
    "reset_at": "2024-01-15T10:30:45.123456"
}
```

## ğŸ“ Logging

Logs are written to console with format:
```
2024-01-15 10:30:45,123 - TokenBucketLimiter - INFO - Rate limit reset for client: api_key_123
```

Configure logging:
```python
import logging
logging.getLogger('rate_limiter').setLevel(logging.DEBUG)
```

## ğŸ¤ Contributing

1. Fork repository
2. Create feature branch
3. Add tests for new features
4. Submit pull request

## ğŸ“„ License

MIT License - See LICENSE file

## ğŸ“ Support

For issues and questions:
1. Check troubleshooting section
2. Review test cases for examples
3. Check algorithm documentation

## ğŸ“ Algorithm Comparisons

| Factor | Token Bucket | Sliding Window | Leaky Bucket | Fixed Window |
|--------|-------------|----------------|-------------|------------|
| Memory | Low | High | Medium | Low |
| Accuracy | Good | Excellent | Good | Fair |
| Burst | Excellent | Limited | Limited | Poor |
| Complexity | Medium | High | Medium | Low |
| Use Case | General | Strict | Smoothing | Simple |
| Performance | Fast | Slower | Medium | Fastest |

## ğŸ”— References

- [Token Bucket Algorithm](https://en.wikipedia.org/wiki/Token_bucket)
- [Sliding Window Counter](https://www.cloudflare.com/learning/rate-limiting/)
- [Leaky Bucket Algorithm](https://en.wikipedia.org/wiki/Leaky_bucket)
- [Rate Limiting Patterns](https://aws.amazon.com/blogs/architecture/)

---

